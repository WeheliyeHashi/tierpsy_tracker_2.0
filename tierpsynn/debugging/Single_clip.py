# %% loading

%matplotlib qt
import pickle
from pathlib import Path

import cv2
import imgstore
import jax
import jax.numpy as jnp
import matplotlib.pyplot as plt
import napari
import numpy as np
from deeptangle import build_model, utils
from deeptangle.predict import non_max_suppression
from tierpsynn.helper.Readers.readLoopBio import readLoopBio
from tierpsynn.helper.Readers.readVideoHDF5 import readVideoHDF5
from tierpsynn.helper.Readers.readVideomp4 import readVideomp4
from skimage.transform import rescale



# %%
Figures = Path("Images_2_analysis").mkdir(exist_ok=True, parents=True)
# model_1 = '/home/weheliye@cscdom.csc.mrc.ac.uk/Desktop/Tierpsy_CNN/tierpsy-tracker-2.0/inference/models/parameters_Final_mixed_train_data_wt_hand_ann_pca_92_epochs_250_2024-04-19_96_cutoff'
# model_2 = '/home/weheliye@cscdom.csc.mrc.ac.uk/Desktop/Tierpsy_CNN/worm_poses/Model/parameters_Final_mixed_train_data_wt_hand_ann_pca_92_epochs_250_2024-04-19_96_cutoff'
# model_3 = '/home/weheliye@cscdom.csc.mrc.ac.uk/Desktop/Tierpsy_CNN/worm_poses/Model/parameters_Final_mixed_train_data_wt_hand_ann_pca_36_epochs_280_2024-06-11_96_cutoff_Tue'
model_4 = "/home/weheliye@cscdom.csc.mrc.ac.uk/Desktop/Tierpsy_CNN/tierpsy-tracker-2.0/inference/models/parameters_Final_mixed_train_data_wt_hand_ann_pca_92_epochs_250_2024-04-19_96_cutoff"
input_vid = "/home/weheliye@cscdom.csc.mrc.ac.uk/behavgenom_mnt/Weheliye/Paper_4_Andre/Data/transfer_2833382_files_c35b8490/RawVideos/MultiwormTest.mp4"
path = Path(model_4)
nframes = 11
n_suggestions = 8
latent_dim = 8
min_frame = 0
skip_frame = 5
max_frame = min_frame + (skip_frame * nframes)
scale_factor = 0.9

pca = 92
cut_of = 96
threshold = 0


def selectVideoReader(params_input: str):
    video_file = params_input
    # open video to read
    isHDF5video = video_file.endswith(".hdf5")

    isLoopBio = video_file.endswith(".yaml")

    isMP4video = video_file.endswith(".mp4")

    if isHDF5video:
        # use tables to read hdf5 with lz4 compression generated by the Gecko
        # plugin
        vid = readVideoHDF5(video_file)
    elif isLoopBio:
        # use opencv VideoCapture
        vid = readLoopBio(video_file)
    elif isMP4video:
        # use opencv VideoCapture
        vid = readVideomp4(video_file)
    else:
        raise Exception("Only HDF5, mp4 and loopbio videos are supported so far")

    if vid.width == 0 or vid.height == 0:
        raise RuntimeError

    return vid


store = selectVideoReader(input_vid)
#%%

def _adpative_thresholding(img, blocksize=31, Constant=1):
    img = (255 - img * 255).astype(np.uint8)
    if len(img.shape) == 3:
        th = np.array(
            [
                cv2.adaptiveThreshold(
                    img[i, :],
                    255,
                    cv2.ADAPTIVE_THRESH_MEAN_C,
                    cv2.THRESH_BINARY,
                    blocksize,
                    Constant,
                )
                == 0
                for i in range(img.shape[0])
            ]
        )
    else:
        th = np.array(
            [
                cv2.adaptiveThreshold(
                    img,
                    255,
                    cv2.ADAPTIVE_THRESH_MEAN_C,
                    cv2.THRESH_BINARY,
                    blocksize,
                    Constant,
                )
                == 0
            ]
        )
    return th


def _mean_bgd(store, max_frame, skip_frame, min_frame=0):
    clip = np.array(
        [
            store.read_frame(frame)[1]
            for frame in range(min_frame, max_frame, skip_frame)
        ]
    )
    mean_image = np.mean(clip, axis=0)
    
    return (255 - mean_image) / 255


def _padding_side(image, n_pads=16, scale_factor= None):
    if scale_factor:
        #image = rescale(image, scale=(scale_factor, scale_factor), anti_aliasing=True)
        # Scale the image with INTER_CUBIC for better quality
        #image = cv2.resize(image, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_CUBIC)
        image = jax.image.resize(image, [int(image.shape[0]*scale_factor),int(image.shape[1]*scale_factor)], method='cubic')


    extra_bottom, extra_right = (
        n_pads - image.shape[0] % n_pads,
        n_pads - image.shape[1] % n_pads,
    )
    return extra_bottom, extra_right


clip = np.array(
    [store.read_frame(frame)[1] for frame in range(min_frame, max_frame, skip_frame)]
)


# bgd, extra_bottom, extra_right = _SVD_bgd(store, store.frame_count, int(store.frame_count/18))
mean_bgd = _mean_bgd(
    store, int(store.tot_frames), int(store.tot_frames / 18)
)

store = selectVideoReader(input_vid)
clip = ((255 - clip)) / 255


clip1 = clip * 255
# %%

th1 = _adpative_thresholding(clip[:]) * clip


th = th1 * ((clip - mean_bgd) > threshold)
th_mean_image = th1 * ((clip - mean_bgd) > threshold)

bgd_image = (clip - mean_bgd) > threshold

if scale_factor:
    #th1 = rescale(th1, scale=(1, scale_factor, scale_factor), anti_aliasing=True)
    # Scale the image with INTER_CUBIC for better quality
    th1 = jax.image.resize(th1, [nframes ,int(th1.shape[1]*scale_factor),int(th1.shape[2]*scale_factor)], method='cubic')

    scale_x, scale_y = (
                        clip.shape[1] / th1.shape[1],
                        clip.shape[2] / th1.shape[2],
                    )

print(th1.shape)
# th = th*masked

extra_bottom, extra_right = _padding_side(mean_bgd, scale_factor=scale_factor)
th = jnp.pad(
    th,
    ((0, 0), (0, extra_bottom), (0, extra_right)),
    mode="constant",
    constant_values=0,
)
th_mean_image = jnp.pad(
    th_mean_image,
    ((0, 0), (0, extra_bottom), (0, extra_right)),
    mode="constant",
    constant_values=0,
)
th1 = jnp.pad(
    th1,
    ((0, 0), (0, extra_bottom), (0, extra_right)),
    mode="constant",
    constant_values=0,
)


clip = jnp.array(th1, dtype=np.float32)
viewer = napari.Viewer()

viewer.add_image(th1)
viewer.add_image(th_mean_image)
viewer.add_image(255 - clip1)
#plt.imshow(clip[0])

clip = clip[None, ...]


with path.joinpath("eigenworms_transform.npy").open("rb") as f:
    A = jnp.load(f)

forward_fn = build_model(A, n_suggestions, latent_dim, nframes)
with path.joinpath("tree.pkl").open("rb") as f:
    tree_struct = pickle.load(f)

leaves, treedef = jax.tree_util.tree_flatten(tree_struct)
with path.joinpath("arrays.npy").open("rb") as f:
    flat_state = [jnp.load(f) for _ in leaves]

state_test = jax.tree_util.tree_unflatten(treedef, flat_state)


# %matplotlib qt

state_single = utils.single_from_sharded(state_test)
params, state_11, opt_state = state_single
# inputs= X[0,Batch_number,:,:,:]
# Y_label = y [0,Batch_number,:,:,:,:]
inputs = clip  # x_label[Batch_number][0,0,:]
# Y_label = y_label[Batch_number][0,0,:]
preds, state_11 = forward_fn.apply(params, state_11, inputs[:], is_training=False)
preds = jax.tree_util.tree_map(lambda x: x[0], preds)
preds = jax.tree_util.tree_map(np.asarray, preds)
best_predictions_idx = non_max_suppression(preds, 0.5, 0.5, cut_of)
final_predictions = jax.tree_util.tree_map(lambda x: x[best_predictions_idx], preds)
# %%
# w,s,p = preds


"""
View images for single spline 
"""
plt.figure()
plt.xlim(0, clip1.shape[2])
plt.ylim(0, clip1.shape[1])
plt.imshow((clip1[5]) / 255, cmap="binary")

for x in final_predictions.w[:, 1]:

    if scale_factor:
        x[:,0] *= scale_x
        x[:,1] *= scale_y


    plt.plot(x[:, 0], x[:, 1], "-", linewidth=1)
    plt.axis("off")
plt.savefig("Images_2_analysis/model_4.jpeg", dpi=1000)


# %%


"""
View images for multiple spline 
"""

w, s, p = preds
plt.figure()
plt.xlim(0, clip1.shape[2])
plt.ylim(0, clip1.shape[1])
plt.imshow((clip1[5]) / 255, cmap="binary")

for j in range(len(s)):
    if s[j] >= 0.5:
        plt.plot(w[j, 1, :, 0], w[j, 1, :, 1], "-", linewidth=1)
        plt.axis("off")


plt.savefig("Images_2_analysis/model_1_all_splines.jpeg", dpi=1000)
# %%


"""
View multiple times 
_
"""

fig, axs = plt.subplots(1, 3, figsize=(30, 10), sharex=True, sharey=True)
k = 0
for s in range(4, 7):
    print(s)
    axs[k].imshow(clip1[s], cmap="gray")
    for x in final_predictions.w[:, k]:
        axs[k].plot(x[:, 0], x[:, 1], "-", linewidth=1)
    axs[k].axis("off")
    k += 1
# %%
